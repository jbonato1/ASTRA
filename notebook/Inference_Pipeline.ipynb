{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "import h5py\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "from visdom import Visdom\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "############### Visualization\n",
    "\n",
    "from ipywidgets import Button, Layout\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display,clear_output,Video\n",
    "from copy import copy\n",
    "import numpy.ma as ma\n",
    "import matplotlib.colors as colors\n",
    "import imageio\n",
    "\n",
    "\n",
    "sys.path.insert(0,'/media/DATA/jbonato/astro_segm/Astro3S/modules/')\n",
    "from gen_single_astro  import filt_im\n",
    "from sel_active_reg_gen import *\n",
    "from model.dense_up import dense_up\n",
    "from test_fun import gen_sc_mask,fix_mask,prob_calc,small_soma_to_proc,common_merge,art_rem_large,art_rem\n",
    "from get_traces import Extr_miniROI,get_signal,get_signals\n",
    "from gui_results import layout\n",
    "\n",
    "\n",
    "# model to import\n",
    "model = dense_up(3)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device1 = torch.device('cpu')#('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "###\n",
    "MAX_ROI_AREA_PROC=30\n",
    "MU_PX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "N=256\n",
    "M=256\n",
    "\n",
    "fov_list = [2]\n",
    "fov_DNN_weights_folder = '/media/DATA/jbonato/astro_segm/weights/dense_up' \n",
    "set_dir='/media/DATA/jbonato/astro_segm/set1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [0, 40, 80, 120, 160],\n",
       " 'blocks': 15,\n",
       " 'threads': 32,\n",
       " 'BPM_ratio': 3,\n",
       " 'bb': 96,\n",
       " 'N_pix_st': 100,\n",
       " 'astr_min': 80,\n",
       " 'percentile': 80,\n",
       " 'pad': 5,\n",
       " 'astro_num': 4,\n",
       " 'init_th_': 0.6,\n",
       " 'decr_dim': 10,\n",
       " 'decr_th': 25,\n",
       " 'corr_int': False,\n",
       " 'gpu_flag': True,\n",
       " 'max_min': array([345,  89]),\n",
       " 'th1_p': 0.25,\n",
       " 'th2_p': 0.1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimDataset_test(Dataset):\n",
    "    def __init__(self,image_set):\n",
    "        self.input_images = image_set    \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "vis_flag = False\n",
    "##### LOAD PARAM DICT\n",
    "with open(set_dir+'.tmp/dict_dataset1.txt', \"rb\") as fp:   #Pickling\n",
    "    dict_param = pickle.load(fp)\n",
    "max_min = dict_param['max_min']\n",
    "dict_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/DATA/jbonato/segm_project/set/2/TSeries-04082019-1513-1251_Ch2__movie_corrected_aligned.tiff\n",
      "Zones 10\n",
      "134 0.91\n",
      "qw 2\n",
      "qw 43\n",
      "157 0.93\n",
      "154 0.9\n",
      "135 0.93\n",
      "qw 7\n",
      "161 0.94\n",
      "qw 27\n",
      "qw 1\n",
      "qw 35\n",
      "qw 1\n",
      "qw 2\n",
      "qw 5\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "ROI NUM 5\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 0\n",
      "ROIS 4\n",
      "mat_out (4, 256, 256)\n",
      "check size (4, 256, 256)\n",
      "ratio 7.3 7\n",
      "ratio 0.43333333333333335 0\n",
      "ratio 1.4 1\n",
      "ratio 0.7666666666666667 0\n",
      "SPLIT DONE (256, 256, 17)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 1\n",
      "ROIS 1\n",
      "mat_out (1, 256, 256)\n",
      "check size (1, 256, 256)\n",
      "ratio 24.933333333333334 24\n",
      "SPLIT DONE (256, 256, 48)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 2\n",
      "ROIS 4\n",
      "mat_out (4, 256, 256)\n",
      "check size (4, 256, 256)\n",
      "ratio 3.033333333333333 3\n",
      "ratio 2.9 2\n",
      "ratio 3.3333333333333335 3\n",
      "ratio 2.8 2\n",
      "SPLIT DONE (256, 256, 13)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 3\n",
      "ROIS 4\n",
      "mat_out (4, 256, 256)\n",
      "check size (4, 256, 256)\n",
      "ratio 5.466666666666667 5\n",
      "ratio 5.4 5\n",
      "ratio 2.5 2\n",
      "ratio 0.8666666666666667 0\n",
      "SPLIT DONE (256, 256, 18)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 4\n",
      "ROIS 6\n",
      "mat_out (6, 256, 256)\n",
      "check size (6, 256, 256)\n",
      "ratio 3.2333333333333334 3\n",
      "ratio 1.8 1\n",
      "ratio 0.4 0\n",
      "ratio 3.533333333333333 3\n",
      "ratio 1.7666666666666666 1\n",
      "ratio 0.6 0\n",
      "SPLIT DONE (256, 256, 13)\n",
      "Extraction: done\n"
     ]
    }
   ],
   "source": [
    "dict_im = {}\n",
    "\n",
    "for jj in fov_list:\n",
    "    #im_list = []\n",
    "    Res_1 = np.zeros((N,M,3))\n",
    "\n",
    "    test_folder_str =str(jj)\n",
    "    if len(test_folder_str)==1:\n",
    "        test_folder_str1='00'+test_folder_str\n",
    "    else:\n",
    "        test_folder_str1='0'+test_folder_str\n",
    "\n",
    "    model.load_state_dict(torch.load(fov_DNN_weights_folder+test_folder_str1+'D1.pt'))\n",
    "    \n",
    "    #collect stack to analyze\n",
    "    \n",
    "    stack_dir = '/media/DATA/jbonato/segm_project/set/'+test_folder_str+'/'\n",
    "\n",
    "    items_stack = os.listdir(stack_dir)\n",
    "\n",
    "    print(stack_dir + items_stack[0])\n",
    "    stack = io.imread(stack_dir + items_stack[0]).astype(np.uint16)\n",
    "    dict_im['t-series_'+test_folder_str1] = stack\n",
    "    frames,_,_ = stack.shape\n",
    "\n",
    "    a_reg = sel_active_reg(stack.astype(np.float32),dict_param)\n",
    "    mask = a_reg.get_mask()\n",
    "    mask = fix_mask(mask)\n",
    "    \n",
    "    #im_list.append([mask,'Active Regions'])\n",
    "    dict_im['Active Regions_'+test_folder_str1] = mask\n",
    "    filter_ = filt_im(stack_dir + items_stack[0],mask,dict_param['bb']-2*dict_param['pad'])\n",
    "    _, image_to_plot = filter_.create_img()\n",
    "    # for other dataset spatia_pp methods can be called from filter_, outputs are stack filtered and spatial map enhanced  \n",
    "    #im_list.append([image_to_plot,'Enhanced'])\n",
    "    dict_im['Enhanced_'+test_folder_str1] = image_to_plot\n",
    "    coord_l = filter_.get_instances()\n",
    "    \n",
    "    assert coord_l!=0, 'Check Active region extraction module'\n",
    "    \n",
    "    \n",
    "    image_stack = np.empty((len(coord_l),dict_param['bb'],dict_param['bb'])) \n",
    "\n",
    "    image_stack,filt_imageL = filter_.save_im()#select the padding val 5 is default\n",
    "    \n",
    "    \n",
    "    image_set = image_stack[:,0,:,:]\n",
    "    image_set = image_set[:,np.newaxis,:,:]\n",
    "\n",
    "    imageL_set = image_to_plot*filt_imageL\n",
    "    imageL_set-=np.mean(imageL_set)\n",
    "    imageL_set= imageL_set[np.newaxis,np.newaxis,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    ######################################## Prob Map\n",
    "    test_datasetL = SimDataset_test(imageL_set)\n",
    "    test_loader = DataLoader(test_datasetL, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    inputs = next(iter(test_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model(inputs)\n",
    "    \n",
    "    pred_mean = pred.data.cpu().numpy()\n",
    "    del test_datasetL,test_loader, inputs,pred\n",
    "    \n",
    "    mean = pred_mean[0]\n",
    "    maxim = np.amax(mean,axis=0)\n",
    "    mean[mean<maxim]=0\n",
    "        \n",
    "    prob_mapPL,sm_ent = prob_calc(mean[1,:,:],max_min[0],max_min[1])\n",
    "    \n",
    "    #im_list.append([prob_mapPL,'Prob. Map'])\n",
    "    dict_im['Prob. Map PL_'+test_folder_str1] = prob_mapPL\n",
    "    #im_list.append([sm_ent,'Prob. Map'])\n",
    "    dict_im['Prob. Map_'+test_folder_str1] = sm_ent\n",
    "    ########################################## putative single cell\n",
    "    test_dataset_S = SimDataset_test(image_set)\n",
    "    test_loader = DataLoader(test_dataset_S, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    \n",
    "    pred_mean=[]\n",
    "    for inputs in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        pred = model(inputs)\n",
    "        pred_mean.append(pred.data.cpu().numpy())\n",
    "        del inputs,pred\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for j in range(1,len(pred_mean)):\n",
    "        pred_mean[0]=np.vstack((pred_mean[0],pred_mean[j]))\n",
    "\n",
    "    prob_map = np.zeros((N,M,2))\n",
    "\n",
    "    for i in range(len(coord_l)):\n",
    "        mean= np.zeros((3,dict_param['bb'],dict_param['bb']))\n",
    "        mean = pred_mean[0][i,:,:,:].copy()\n",
    "        \n",
    "        maxim = np.amax(mean,axis=0)\n",
    "        mean[mean<maxim]=0\n",
    "        mean[mean>=maxim]=1\n",
    "\n",
    "        small_soma = small_soma_to_proc(mean[1,:,:],N = int((2/3)*max_min[1])) ####remove too small somata segmentated\n",
    "        mean[0,:,:]+=small_soma\n",
    "        mean[1,:,:]-=small_soma\n",
    "        \n",
    "        coord = coord_l[i]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],0] += mean[0,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],1] += mean[1,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "\n",
    "\n",
    "\n",
    "    Res_1[:,:,0] -= Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    ######### can be wrapped\n",
    "    \n",
    "    soma_f = common_merge(Res_1[:,:,1],sm_ent)\n",
    "    Res_1[:,:,1]=soma_f\n",
    "\n",
    "    #remove possible artifacts\n",
    "    small_soma = small_soma_to_proc(Res_1[:,:,1],int(0.9*max_min[1]),dilation=False)\n",
    "    Res_1[:,:,1]-=small_soma\n",
    "\n",
    "    Res_1[:,:,0] = Res_1[:,:,0]-Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    #remove large region classified as soma Area>500\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=int(1.15*max_min[0]))\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=max_min[0])\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "    #remove processes without soma\n",
    "    Res_1_filt = art_rem(Res_1[:,:,1],Res_1[:,:,0])\n",
    "    Res_1*=Res_1_filt[:,:,np.newaxis]\n",
    "    \n",
    "    #im_list.append([Res_1,'Final Mask'])\n",
    "    dict_im['Final_Mask_'+test_folder_str1] = Res_1\n",
    "    print(20*'%')\n",
    "    #######################################################################################################\n",
    "    #Visualization of images\n",
    "    if vis_flag:\n",
    "        vis = Visdom(port=8097, server=\"http://localhost\",env='inference_plot')\n",
    "        for key in dict_im.keys():\n",
    "            image = dict_im[key]\n",
    "            fig, ax = plt.subplots(figsize=(4,4))\n",
    "            ax.imshow(image)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(key)\n",
    "            vis.matplot(fig)\n",
    "            plt.close(fig)\n",
    "    \n",
    "    #### Extraction can be wrapped into a function\n",
    "    single_astro_roi = gen_sc_mask(dict_im['Final_Mask_'+test_folder_str1])\n",
    "    dict_im['Single_cell_mask_'+test_folder_str1] = single_astro_roi\n",
    "    dict_roi={}\n",
    "    dict_traces={}\n",
    "    dict_im['Cell_num_'+test_folder_str1] = single_astro_roi.shape[0]\n",
    "    print(\"ROI NUM\",single_astro_roi.shape[0])\n",
    "    for s_roi_num in range(single_astro_roi.shape[0]):\n",
    "        print(50*'%','Extracting cell:',s_roi_num)\n",
    "        constr_split_roi = Extr_miniROI(MAX_ROI_AREA_PROC,MU_PX,single_astro_roi[s_roi_num,:,:,0],single_astro_roi[s_roi_num,:,:,1],True)\n",
    "        arr_out_proc = constr_split_roi.get_miniROI()\n",
    "        if  s_roi_num==0:\n",
    "            list_out=arr_out_proc\n",
    "        else:\n",
    "            list_out = np.dstack((list_out,arr_out_proc))\n",
    "        name = str(s_roi_num)\n",
    "        dict_roi['Soma_'+f'{name:0>3}'] = np.where(single_astro_roi[s_roi_num,:,:,1]==1)\n",
    "        dict_traces['Soma_'+f'{name:0>3}'] = get_signal(single_astro_roi[s_roi_num,:,:,1],dict_im['t-series_'+test_folder_str1])\n",
    "        for proc_num in range(arr_out_proc.shape[2]):\n",
    "            name_proc = str(proc_num)\n",
    "            dict_roi['Proc_'+f'{name:0>3}'+'_'+f'{name_proc:0>3}'] = np.where(arr_out_proc[:,:,proc_num]==1)\n",
    "            dict_traces['Proc_'+f'{name:0>3}'+'_'+f'{name_proc:0>3}']  = get_signal(arr_out_proc[:,:,proc_num],dict_im['t-series_'+test_folder_str1])\n",
    "        print('Extraction: done')\n",
    "    \n",
    "    dict_im['Signals_extr_'+test_folder_str1] = dict_traces\n",
    "    dict_im['ROI_'+test_folder_str1] = dict_roi\n",
    "    \n",
    "    #### for Visualization purposes\n",
    "    list_out = np.dstack((list_out,dict_im['Final_Mask_'+test_folder_str1][:,:,1:]))\n",
    "    dict_im['Final_Mask_fraction_'+test_folder_str1] = list_out\n",
    "    #### save dict\n",
    "    pickle.dump(dict_im, open( \"inference_ex.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 111)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t-series_002', 'Active Regions_002', 'Enhanced_002', 'Prob. Map PL_002', 'Prob. Map_002', 'Final_Mask_002', 'Cell_num_002', 'Signals_extr_002', 'ROI_002', 'Final_Mask_fraction_002'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_im.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Soma_000', 'Proc_000_000', 'Proc_000_001', 'Proc_000_002', 'Proc_000_003', 'Proc_000_004', 'Proc_000_005', 'Proc_000_006', 'Proc_000_007', 'Proc_000_008', 'Proc_000_009', 'Proc_000_010', 'Proc_000_011', 'Proc_000_012', 'Proc_000_013', 'Proc_000_014', 'Proc_000_015', 'Proc_000_016', 'Soma_001', 'Proc_001_000', 'Proc_001_001', 'Proc_001_002', 'Proc_001_003', 'Proc_001_004', 'Proc_001_005', 'Proc_001_006', 'Proc_001_007', 'Proc_001_008', 'Proc_001_009', 'Proc_001_010', 'Proc_001_011', 'Proc_001_012', 'Proc_001_013', 'Proc_001_014', 'Proc_001_015', 'Proc_001_016', 'Proc_001_017', 'Proc_001_018', 'Proc_001_019', 'Proc_001_020', 'Proc_001_021', 'Proc_001_022', 'Proc_001_023', 'Proc_001_024', 'Proc_001_025', 'Proc_001_026', 'Proc_001_027', 'Proc_001_028', 'Proc_001_029', 'Proc_001_030', 'Proc_001_031', 'Proc_001_032', 'Proc_001_033', 'Proc_001_034', 'Proc_001_035', 'Proc_001_036', 'Proc_001_037', 'Proc_001_038', 'Proc_001_039', 'Proc_001_040', 'Proc_001_041', 'Proc_001_042', 'Proc_001_043', 'Proc_001_044', 'Proc_001_045', 'Proc_001_046', 'Proc_001_047', 'Soma_002', 'Proc_002_000', 'Proc_002_001', 'Proc_002_002', 'Proc_002_003', 'Proc_002_004', 'Proc_002_005', 'Proc_002_006', 'Proc_002_007', 'Proc_002_008', 'Proc_002_009', 'Proc_002_010', 'Proc_002_011', 'Proc_002_012', 'Soma_003', 'Proc_003_000', 'Proc_003_001', 'Proc_003_002', 'Proc_003_003', 'Proc_003_004', 'Proc_003_005', 'Proc_003_006', 'Proc_003_007', 'Proc_003_008', 'Proc_003_009', 'Proc_003_010', 'Proc_003_011', 'Proc_003_012', 'Proc_003_013', 'Proc_003_014', 'Proc_003_015', 'Proc_003_016', 'Proc_003_017', 'Soma_004', 'Proc_004_000', 'Proc_004_001', 'Proc_004_002', 'Proc_004_003', 'Proc_004_004', 'Proc_004_005', 'Proc_004_006', 'Proc_004_007', 'Proc_004_008', 'Proc_004_009', 'Proc_004_010', 'Proc_004_011', 'Proc_004_012'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_im['ROI_002'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 111)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_im['Final_Mask_fraction_002'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['002']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fov_name = []\n",
    "for j in fov_list:\n",
    "    j = str(j)\n",
    "    if len(j)==1:\n",
    "        j='00'+j\n",
    "    else:\n",
    "        j='0'+j\n",
    "    fov_name.append(j)\n",
    "fov_name\n",
    "hbox,button,display_plot = layout(fov_name,dict_im)\n",
    "display(hbox)\n",
    "button.on_click(display_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Soma_000', 'Proc_000_000', 'Proc_000_001', 'Proc_000_002', 'Proc_000_003', 'Proc_000_004', 'Proc_000_005', 'Proc_000_006', 'Proc_000_007', 'Proc_000_008', 'Proc_000_009', 'Proc_000_010', 'Proc_000_011', 'Proc_000_012', 'Proc_000_013', 'Proc_000_014', 'Proc_000_015', 'Proc_000_016', 'Soma_001', 'Proc_001_000', 'Proc_001_001', 'Proc_001_002', 'Proc_001_003', 'Proc_001_004', 'Proc_001_005', 'Proc_001_006', 'Proc_001_007', 'Proc_001_008', 'Proc_001_009', 'Proc_001_010', 'Proc_001_011', 'Proc_001_012', 'Proc_001_013', 'Proc_001_014', 'Proc_001_015', 'Proc_001_016', 'Proc_001_017', 'Proc_001_018', 'Proc_001_019', 'Proc_001_020', 'Proc_001_021', 'Proc_001_022', 'Proc_001_023', 'Proc_001_024', 'Proc_001_025', 'Proc_001_026', 'Proc_001_027', 'Proc_001_028', 'Proc_001_029', 'Proc_001_030', 'Proc_001_031', 'Proc_001_032', 'Proc_001_033', 'Proc_001_034', 'Proc_001_035', 'Proc_001_036', 'Proc_001_037', 'Proc_001_038', 'Proc_001_039', 'Proc_001_040', 'Proc_001_041', 'Proc_001_042', 'Proc_001_043', 'Proc_001_044', 'Proc_001_045', 'Proc_001_046', 'Proc_001_047', 'Soma_002', 'Proc_002_000', 'Proc_002_001', 'Proc_002_002', 'Proc_002_003', 'Proc_002_004', 'Proc_002_005', 'Proc_002_006', 'Proc_002_007', 'Proc_002_008', 'Proc_002_009', 'Proc_002_010', 'Proc_002_011', 'Proc_002_012', 'Soma_003', 'Proc_003_000', 'Proc_003_001', 'Proc_003_002', 'Proc_003_003', 'Proc_003_004', 'Proc_003_005', 'Proc_003_006', 'Proc_003_007', 'Proc_003_008', 'Proc_003_009', 'Proc_003_010', 'Proc_003_011', 'Proc_003_012', 'Proc_003_013', 'Proc_003_014', 'Proc_003_015', 'Proc_003_016', 'Proc_003_017', 'Soma_004', 'Proc_004_000', 'Proc_004_001', 'Proc_004_002', 'Proc_004_003', 'Proc_004_004', 'Proc_004_005', 'Proc_004_006', 'Proc_004_007', 'Proc_004_008', 'Proc_004_009', 'Proc_004_010', 'Proc_004_011', 'Proc_004_012'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_im['ROI_002'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15,\n",
       "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20]),\n",
       " array([79, 80, 81, 78, 79, 80, 81, 82, 83, 84, 88, 89, 90, 91, 77, 78, 79,\n",
       "        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 76, 77, 78,\n",
       "        79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 76,\n",
       "        77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,\n",
       "        76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92,\n",
       "        93, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92,\n",
       "        78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 79, 80, 81,\n",
       "        82, 83, 84, 85, 86, 87, 88, 89, 90, 82, 83, 84, 85, 86, 87, 88]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_im['ROI_002']['Soma_000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2db2c5130204761b64ff09ce8e858c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(height='400px', width='1200px')), HBox(children=(VBox(children=(Dropdown(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

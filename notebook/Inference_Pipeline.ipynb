{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "import h5py\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "from visdom import Visdom\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "############### Visualization\n",
    "\n",
    "from ipywidgets import Button, Layout\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display,clear_output,Video\n",
    "from copy import copy\n",
    "import numpy.ma as ma\n",
    "import matplotlib.colors as colors\n",
    "import imageio\n",
    "\n",
    "\n",
    "sys.path.insert(0,'/media/DATA/jbonato/astro_segm/Astro3S/modules/')\n",
    "from gen_single_astro  import filt_im\n",
    "from sel_active_reg_gen import *\n",
    "from model.dense_up import dense_up\n",
    "from test_fun import *\n",
    "\n",
    "# model to import\n",
    "model = dense_up(3)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device1 = torch.device('cpu')#('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "###\n",
    "MAX_ROI_AREA_PROC=40\n",
    "MU_PX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "N=256\n",
    "M=256\n",
    "\n",
    "fov_list = [4]\n",
    "fov_DNN_weights_folder = '/media/DATA/jbonato/astro_segm/weights/dense_up' \n",
    "set_dir='/media/DATA/jbonato/astro_segm/set1/'\n",
    "\n",
    "####### to rem\n",
    "from sklearn.cluster import KMeans\n",
    "class Extr_miniROI():\n",
    "    \n",
    "    def __init__(self,Area_mu,mu_px,proc_to_split,split_proc=False):\n",
    "        \n",
    "        \n",
    "        self.Area_mu = Area_mu\n",
    "        self.mu_px = mu_px\n",
    "        \n",
    "        self.Area_px = Area_mu/mu_px**2\n",
    "        self.proc_to_split = proc_to_split\n",
    "        self.split_proc = split_proc\n",
    "    \n",
    "    @staticmethod\n",
    "    def det_conn_comp(processes):\n",
    "        print(processes.shape)\n",
    "        N,M = processes.shape\n",
    "        num,comp = cv2.connectedComponents(processes.astype(np.uint8))\n",
    "        print(num)\n",
    "        processes_out = np.zeros((num-1,N,M))\n",
    "        for k in range(1,num):\n",
    "            print(k)\n",
    "            pt = np.where(comp==k)\n",
    "            processes_out[k-1,pt[0],pt[1]]=1\n",
    "        return processes_out\n",
    "\n",
    "    def get_k(self,area):\n",
    "        return area/self.Area_px\n",
    "    \n",
    "    def get_miniROI(self):\n",
    "        if self.split_proc :\n",
    "            self.proc_to_split = self.det_conn_comp(self.proc_to_split)\n",
    "        \n",
    "        Nroi,H,W = self.proc_to_split.shape\n",
    "        collROI = []\n",
    "        for i in range(Nroi):\n",
    "            N = np.sum(self.proc_to_split[i,:,:])\n",
    "            k = self.get_k(N)\n",
    "            print(k,int(k))\n",
    "            if int(k)<=1:\n",
    "                collROI.append(self.proc_to_split[i,:,:][:,:,np.newaxis])\n",
    "            else:\n",
    "                rr = k.astype(np.int64)\n",
    "                print(rr.dtype)\n",
    "                buff = np.zeros((H,W,rr))\n",
    "                pt = np.where(self.proc_to_split[i,:,:]==1)\n",
    "                X = np.asarray([pt[0],pt[1]]).T\n",
    "                \n",
    "                kmeans = KMeans(n_clusters=int(k), random_state=0).fit(X)\n",
    "                labels = kmeans.labels_\n",
    "                for j in range(int(k)):\n",
    "                    pt_lb = np.where(labels==j)\n",
    "                    buff[X[pt_lb[0],0],X[pt_lb[0],1],j]=1\n",
    "                collROI.append(buff)\n",
    "        out = collROI[0]       \n",
    "        for i in range(len(collROI)):  \n",
    "            #print(collROI[i].shape)\n",
    "            out = np.dstack((out,collROI[i]))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_signals(roi,stack):\n",
    "    T,_,_ = stack.shape\n",
    "    _,_,N = roi.shape\n",
    "    print(roi.shape)\n",
    "    signals = []\n",
    "    for i in range(N-1):\n",
    "        pt = np.where(roi[:,:,i]==1)\n",
    "        #ev add single pixels rem\n",
    "        signals.append(np.mean(stack[:,pt[0],pt[1]],axis=1))\n",
    "    return signals\n",
    "\n",
    "def get_signal(roi,stack):\n",
    "    pt = np.where(roi==1)\n",
    "    return np.mean(stack[:,pt[0],pt[1]],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [0, 40, 80, 120, 160],\n",
       " 'blocks': 15,\n",
       " 'threads': 32,\n",
       " 'BPM_ratio': 3,\n",
       " 'bb': 96,\n",
       " 'N_pix_st': 100,\n",
       " 'astr_min': 80,\n",
       " 'percentile': 80,\n",
       " 'pad': 5,\n",
       " 'astro_num': 4,\n",
       " 'init_th_': 0.6,\n",
       " 'decr_dim': 10,\n",
       " 'decr_th': 25,\n",
       " 'corr_int': False,\n",
       " 'gpu_flag': True,\n",
       " 'max_min': array([345,  89]),\n",
       " 'th1_p': 0.25,\n",
       " 'th2_p': 0.1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimDataset_test(Dataset):\n",
    "    def __init__(self,image_set):\n",
    "        self.input_images = image_set    \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "vis_flag = False\n",
    "##### LOAD PARAM DICT\n",
    "with open(set_dir+'.tmp/dict_dataset1.txt', \"rb\") as fp:   #Pickling\n",
    "    dict_param = pickle.load(fp)\n",
    "max_min = dict_param['max_min']\n",
    "dict_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/DATA/jbonato/segm_project/set/4/TSeries-04112019-1605-1257_Ch2__movie_corrected_aligned.tiff\n",
      "Zones 7\n",
      "qw 25\n",
      "186 0.92\n",
      "184 0.93\n",
      "263 0.91\n",
      "309 0.95\n",
      "qw 1\n",
      "224 0.93\n",
      "104 0.89\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "ROI NUM 5\n",
      "(256, 256)\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "0.15 0\n",
      "0.4 0\n",
      "5.35 5\n",
      "int64\n",
      "(256, 256)\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "0.775 0\n",
      "0.475 0\n",
      "4.7 4\n",
      "int64\n",
      "(256, 256)\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2.05 2\n",
      "int64\n",
      "1.45 1\n",
      "3.525 3\n",
      "int64\n",
      "1.7 1\n",
      "(256, 256)\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4.325 4\n",
      "int64\n",
      "0.55 0\n",
      "0.05 0\n",
      "0.5 0\n",
      "(256, 256)\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "2.975 2\n",
      "int64\n",
      "1.875 1\n",
      "0.275 0\n",
      "0.975 0\n",
      "(256, 256)\n",
      "19\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "0.15 0\n",
      "0.4 0\n",
      "5.35 5\n",
      "int64\n",
      "0.775 0\n",
      "0.475 0\n",
      "4.7 4\n",
      "int64\n",
      "2.05 2\n",
      "int64\n",
      "1.45 1\n",
      "4.325 4\n",
      "int64\n",
      "3.525 3\n",
      "int64\n",
      "1.7 1\n",
      "0.55 0\n",
      "0.05 0\n",
      "0.5 0\n",
      "2.975 2\n",
      "int64\n",
      "1.875 1\n",
      "0.275 0\n",
      "0.975 0\n"
     ]
    }
   ],
   "source": [
    "dict_im = {}\n",
    "\n",
    "for jj in fov_list:\n",
    "    #im_list = []\n",
    "    Res_1 = np.zeros((N,M,3))\n",
    "\n",
    "    test_folder_str =str(jj)\n",
    "    if len(test_folder_str)==1:\n",
    "        test_folder_str1='00'+test_folder_str\n",
    "    else:\n",
    "        test_folder_str1='0'+test_folder_str\n",
    "\n",
    "    model.load_state_dict(torch.load(fov_DNN_weights_folder+test_folder_str1+'D1.pt'))\n",
    "    \n",
    "    #collect stack to analyze\n",
    "    \n",
    "    stack_dir = '/media/DATA/jbonato/segm_project/set/'+test_folder_str+'/'\n",
    "\n",
    "    items_stack = os.listdir(stack_dir)\n",
    "\n",
    "    print(stack_dir + items_stack[0])\n",
    "    stack = io.imread(stack_dir + items_stack[0]).astype(np.uint16)\n",
    "    dict_im['t-series_'+test_folder_str1] = stack\n",
    "    frames,_,_ = stack.shape\n",
    "\n",
    "    a_reg = sel_active_reg(stack.astype(np.float32),dict_param)\n",
    "    mask = a_reg.get_mask()\n",
    "    mask = fix_mask(mask)\n",
    "    #im_list.append([mask,'Active Regions'])\n",
    "    dict_im['Active Regions_'+test_folder_str1] = mask\n",
    "    filter_ = filt_im(stack_dir + items_stack[0],mask,dict_param['bb']-2*dict_param['pad'])\n",
    "    _, image_to_plot = filter_.create_img()\n",
    "    # for other dataset spatia_pp methods can be called from filter_, outputs are stack filtered and spatial map enhanced  \n",
    "    #im_list.append([image_to_plot,'Enhanced'])\n",
    "    dict_im['Enhanced_'+test_folder_str1] = image_to_plot\n",
    "    coord_l = filter_.get_instances()\n",
    "    \n",
    "    assert coord_l!=0, 'Check Active region extraction module'\n",
    "    \n",
    "    \n",
    "    image_stack = np.empty((len(coord_l),dict_param['bb'],dict_param['bb'])) \n",
    "\n",
    "    image_stack,filt_imageL = filter_.save_im()#select the padding val 5 is default\n",
    "    \n",
    "    \n",
    "    image_set = image_stack[:,0,:,:]\n",
    "    image_set = image_set[:,np.newaxis,:,:]\n",
    "\n",
    "    imageL_set = image_to_plot*filt_imageL\n",
    "    imageL_set-=np.mean(imageL_set)\n",
    "    imageL_set= imageL_set[np.newaxis,np.newaxis,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    ######################################## Prob Map\n",
    "    test_datasetL = SimDataset_test(imageL_set)\n",
    "    test_loader = DataLoader(test_datasetL, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    inputs = next(iter(test_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model(inputs)\n",
    "    \n",
    "    pred_mean = pred.data.cpu().numpy()\n",
    "    del test_datasetL,test_loader, inputs,pred\n",
    "    \n",
    "    mean = pred_mean[0]\n",
    "    maxim = np.amax(mean,axis=0)\n",
    "    mean[mean<maxim]=0\n",
    "        \n",
    "    prob_mapPL,sm_ent = prob_calc(mean[1,:,:],max_min[0],max_min[1])\n",
    "    \n",
    "    #im_list.append([prob_mapPL,'Prob. Map'])\n",
    "    dict_im['Prob. Map PL_'+test_folder_str1] = prob_mapPL\n",
    "    #im_list.append([sm_ent,'Prob. Map'])\n",
    "    dict_im['Prob. Map_'+test_folder_str1] = sm_ent\n",
    "    ########################################## putative single cell\n",
    "    test_dataset_S = SimDataset_test(image_set)\n",
    "    test_loader = DataLoader(test_dataset_S, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    \n",
    "    pred_mean=[]\n",
    "    for inputs in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        pred = model(inputs)\n",
    "        pred_mean.append(pred.data.cpu().numpy())\n",
    "        del inputs,pred\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for j in range(1,len(pred_mean)):\n",
    "        pred_mean[0]=np.vstack((pred_mean[0],pred_mean[j]))\n",
    "\n",
    "    prob_map = np.zeros((N,M,2))\n",
    "\n",
    "    for i in range(len(coord_l)):\n",
    "        mean= np.zeros((3,dict_param['bb'],dict_param['bb']))\n",
    "        mean = pred_mean[0][i,:,:,:].copy()\n",
    "        \n",
    "        maxim = np.amax(mean,axis=0)\n",
    "        mean[mean<maxim]=0\n",
    "        mean[mean>=maxim]=1\n",
    "\n",
    "        small_soma = small_soma_to_proc(mean[1,:,:],N = int((2/3)*max_min[1])) ####remove too small somata segmentated\n",
    "        mean[0,:,:]+=small_soma\n",
    "        mean[1,:,:]-=small_soma\n",
    "        \n",
    "        coord = coord_l[i]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],0] += mean[0,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],1] += mean[1,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "\n",
    "\n",
    "\n",
    "    Res_1[:,:,0] -= Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    soma_f = common_merge(Res_1[:,:,1],sm_ent)\n",
    "    Res_1[:,:,1]=soma_f\n",
    "\n",
    "    #remove possible artifacts\n",
    "    small_soma = small_soma_to_proc(Res_1[:,:,1],int(0.9*max_min[1]),dilation=False)\n",
    "    Res_1[:,:,1]-=small_soma\n",
    "\n",
    "    Res_1[:,:,0] = Res_1[:,:,0]-Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    #remove large region classified as soma Area>500\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=int(1.15*max_min[0]))\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=max_min[0])\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "    #remove processes without soma\n",
    "    Res_1_filt = art_rem(Res_1[:,:,1],Res_1[:,:,0])\n",
    "    Res_1*=Res_1_filt[:,:,np.newaxis]\n",
    "    \n",
    "    #im_list.append([Res_1,'Final Mask'])\n",
    "    dict_im['Final_Mask_'+test_folder_str1] = Res_1\n",
    "    print(20*'%')\n",
    "    #######################################################################################################\n",
    "    #Visualization of images\n",
    "    if vis_flag:\n",
    "        vis = Visdom(port=8097, server=\"http://localhost\",env='inference_plot')\n",
    "        for key in dict_im.keys():\n",
    "            image = dict_im[key]\n",
    "            fig, ax = plt.subplots(figsize=(4,4))\n",
    "            ax.imshow(image)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(key)\n",
    "            vis.matplot(fig)\n",
    "            plt.close(fig)\n",
    "    \n",
    "    ####\n",
    "    single_astro_roi = gen_sc_mask(dict_im['Final_Mask_'+test_folder_str1])\n",
    "    dict_roi={}\n",
    "    dict_traces={}\n",
    "    \n",
    "    dict_im['Cell_num_'+test_folder_str1] = single_astro_roi.shape[0]\n",
    "    print(\"ROI NUM\",single_astro_roi.shape[0])\n",
    "    for s_roi_num in range(single_astro_roi.shape[0]):\n",
    "        constr_split_roi = Extr_miniROI(MAX_ROI_AREA_PROC,MU_PX,single_astro_roi[s_roi_num,:,:,0],True)\n",
    "        arr_out_proc = constr_split_roi.get_miniROI()\n",
    "        \n",
    "        name = str(s_roi_num)\n",
    "        dict_roi['Soma_'+f'{name:0>3}'] = np.where(single_astro_roi[s_roi_num,:,:,1]==1)\n",
    "        dict_traces['Soma_'+f'{name:0>3}'] = get_signal(single_astro_roi[s_roi_num,:,:,1],dict_im['t-series_'+test_folder_str1])\n",
    "        for proc_num in range(arr_out_proc.shape[2]):\n",
    "            name_proc = str(proc_num)\n",
    "            dict_roi['Proc_'+f'{name:0>3}'+'_'+f'{name_proc:0>3}'] = np.where(arr_out_proc[:,:,proc_num]==1)\n",
    "            dict_traces['Proc_'+f'{name:0>3}'+'_'+f'{name_proc:0>3}']  = get_signal(arr_out_proc[:,:,proc_num],dict_im['t-series_'+test_folder_str1])\n",
    "    \n",
    "    dict_im['Signals_extr_'+test_folder_str1] = dict_traces\n",
    "    dict_im['ROI_'+test_folder_str1] = dict_roi\n",
    "    \n",
    "    #### for Visualization purposes\n",
    "    constr_split_roi = Extr_miniROI(MAX_ROI_AREA_PROC,MU_PX,dict_im['Final_Mask_'+test_folder_str1][:,:,0],True)\n",
    "    list_out = constr_split_roi.get_miniROI()\n",
    "\n",
    "    list_out = np.dstack((list_out,dict_im['Final_Mask_'+test_folder_str1][:,:,1:]))\n",
    "    dict_im['Final_Mask_fraction_'+test_folder_str1] = list_out\n",
    "    \n",
    "    ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Soma_000', 'Proc_000_000', 'Proc_000_001', 'Proc_000_002', 'Proc_000_003', 'Proc_000_004', 'Proc_000_005', 'Proc_000_006', 'Proc_000_007', 'Soma_001', 'Proc_001_000', 'Proc_001_001', 'Proc_001_002', 'Proc_001_003', 'Proc_001_004', 'Proc_001_005', 'Proc_001_006', 'Soma_002', 'Proc_002_000', 'Proc_002_001', 'Proc_002_002', 'Proc_002_003', 'Proc_002_004', 'Proc_002_005', 'Proc_002_006', 'Proc_002_007', 'Proc_002_008', 'Soma_003', 'Proc_003_000', 'Proc_003_001', 'Proc_003_002', 'Proc_003_003', 'Proc_003_004', 'Proc_003_005', 'Proc_003_006', 'Proc_003_007', 'Proc_003_008', 'Proc_003_009', 'Proc_003_010', 'Soma_004', 'Proc_004_000', 'Proc_004_001', 'Proc_004_002', 'Proc_004_003', 'Proc_004_004', 'Proc_004_005', 'Proc_004_006'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_traces.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(np.sum(w[0,:,:,:],axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cont(mask):\n",
    "    N,M,c = mask.shape\n",
    "    \n",
    "    sm_c = np.zeros((N,M))\n",
    "    pr_c = np.zeros((N,M))\n",
    "    for cnt in range(c-1):\n",
    "        \n",
    "        if cnt==c-2:\n",
    "            \n",
    "            contours, hierarchy = cv2.findContours(np.uint8(mask[:,:,cnt]), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            for j in contours:\n",
    "                \n",
    "                sm_c[j[:,0,1],j[:,0,0]]=1\n",
    "        else:\n",
    "            \n",
    "            contours, hierarchy = cv2.findContours(np.uint8(mask[:,:,cnt]), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "            for j in contours:\n",
    "                pr_c[j[:,0,1],j[:,0,0]]=1\n",
    "    pr_c[pr_c>1]=1\n",
    "    return np.where(sm_c==1),np.where(pr_c==1)#sm_c,pr_c#\n",
    "\n",
    "def draw_on_Im(image,c_sm,c_pr):\n",
    "    image_pl = image.copy()\n",
    "    image_pl = image_pl.astype(np.float64)\n",
    "    maxim = image_pl.max()\n",
    "    image_pl/=maxim\n",
    "    image_pl[c_sm]=4\n",
    "    image_pl[c_pr]=10\n",
    "    return image_pl\n",
    "\n",
    "\n",
    "def get_im(mask,image):\n",
    "    sm_net,pr_net = draw_cont(mask)\n",
    "    image_net = draw_on_Im(image,sm_net,pr_net)\n",
    "    return image_net\n",
    "\n",
    "\n",
    "\n",
    "def gen_mask_sc(dict_,cell_num,im_shape):\n",
    "    roi_list = []\n",
    "\n",
    "    for key in dict_.keys():\n",
    "        if 'Proc_'+f'{str(cell_num):0>3}'+'_' in key:\n",
    "            pt = dict_[key]\n",
    "            buff = np.zeros(im_shape)\n",
    "            buff[pt[0],pt[1]]=1\n",
    "            roi_list.append(buff)\n",
    "    \n",
    "    pt = dict_['Soma_'+f'{str(cell_num):0>3}']\n",
    "    buff = np.zeros(im_shape)\n",
    "    buff[pt[0],pt[1]]=1\n",
    "    roi_list.append(buff)\n",
    "    \n",
    "    buff = np.zeros(im_shape)\n",
    "    roi_list.append(buff)\n",
    "    \n",
    "    out = roi_list[0]\n",
    "    for i in range(1,len(roi_list)):  \n",
    "        \n",
    "        out = np.dstack((out,roi_list[i]))\n",
    "    return out\n",
    "\n",
    "def get_f0(traces):\n",
    "    baseline = np.zeros_like(traces).astype(np.float32)\n",
    "    for i in range(traces.shape[1]):\n",
    "        if i<45:\n",
    "            st=0\n",
    "        else:\n",
    "            st=i-45\n",
    "        if i>frames-45:\n",
    "            end = -1\n",
    "        else:\n",
    "            end=i+45\n",
    "\n",
    "        baseline[:,i] = np.percentile(traces[:,st:end],20,axis=1)\n",
    "\n",
    "    return baseline\n",
    "    \n",
    "def plot_traces(dict_,cell_num,ax):\n",
    "    MAX_traces = 7\n",
    "    \n",
    "    traces = []\n",
    "    name=[]\n",
    "    traces.append(dict_['Soma_'+f'{str(cell_num):0>3}'])\n",
    "    name.append('Soma')\n",
    "    cnt=1\n",
    "    for key in dict_.keys():\n",
    "        if 'Proc_'+f'{str(cell_num):0>3}'+'_' in key and cnt<= MAX_traces:\n",
    "            traces.append(dict_[key])\n",
    "            name.append('Proc.'+str(key[-3:]))\n",
    "            cnt+=1\n",
    "    traces = np.asarray(traces)\n",
    "    print(traces.shape)\n",
    "    f0 = get_f0(traces)\n",
    "    traces = (traces-f0)/f0\n",
    "    delta = 0\n",
    "    for j in range(MAX_traces):\n",
    "        ax.plot(np.arange(traces.shape[1]),traces[j,:]+delta)\n",
    "        ax.text(x = 0, y= traces[j,:].max()/2+delta, s =name[j] , rotation = 0,fontsize= 8)\n",
    "        delta+= traces[j,:].max()+0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['004']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fov_name = []\n",
    "for j in fov_list:\n",
    "    j = str(j)\n",
    "    if len(j)==1:\n",
    "        j='00'+j\n",
    "    else:\n",
    "        j='0'+j\n",
    "    fov_name.append(j)\n",
    "fov_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Cell_num_002'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f6522cd93575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_im\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cell_num_002'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Cell_num_002'"
     ]
    }
   ],
   "source": [
    "dict_im['Cell_num_002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bfa4720bd346c8a11c4a3df2496901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Output(layout=Layout(height='400px', width='1200px')), Dropdown(description='FOVâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num= widgets.Dropdown(\n",
    "    options=fov_name,\n",
    "    value=fov_name[0],\n",
    "    description='FOV',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "cell_num= widgets.Dropdown(\n",
    "    options=[i for i in range(dict_im['Cell_num_'+num.value])],\n",
    "    value=0,\n",
    "    description='cell',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "mapped = widgets.Dropdown(\n",
    "    options=[('inferno',plt.cm.inferno), ('viridis',plt.cm.viridis), ('Greys',plt.cm.gray)],\n",
    "    value=plt.cm.gray,\n",
    "    description='Cmap:',\n",
    "    disabled=False,\n",
    ")\n",
    "projection =  widgets.Dropdown(\n",
    "    options=['median', 'max', 'mean'],\n",
    "    value='median',\n",
    "    description='Projection:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "ROI_type =  widgets.Dropdown(\n",
    "    options=[('All','_'), ('Fraction','_fraction_')],\n",
    "    value='_',\n",
    "    description='Roi Type',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Plot',\n",
    ")\n",
    "out=widgets.Output(layout=Layout(width='1200px', height='400px'))\n",
    "out2=widgets.Output(layout=Layout(width='400px', height='400px'))\n",
    "button=widgets.Button(description='Next')\n",
    "vbox=widgets.VBox(children=(out,num,cell_num,mapped,projection,ROI_type,button))\n",
    "hbox=widgets.HBox(children=(vbox,out2))\n",
    "display(hbox)\n",
    "\n",
    "def plot2(b=None):\n",
    "    id_ = num.value    \n",
    "    stack = dict_im['t-series_'+id_]\n",
    "    T,N,M = stack.shape\n",
    "    \n",
    "    Res_mat = dict_im['Final_Mask'+ROI_type.value+id_]\n",
    "    video = np.empty((stack.shape[0],256,256),dtype=np.uint8)\n",
    "    for j in range(stack.shape[0]):\n",
    "        img = stack[j,:,:]\n",
    "        bl = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        video[j,:,:]=bl\n",
    "\n",
    "    imageio.mimwrite('test2.mp4',video, fps=30);\n",
    "    with out2:\n",
    "        clear_output(wait=True)\n",
    "        display(Video('test2.mp4',width=400,height=400))\n",
    "    if projection.value=='median':\n",
    "        im = np.median(stack,axis=0)\n",
    "    elif projection.value == 'mean':\n",
    "        im = np.mean(stack,axis=0)\n",
    "    else:\n",
    "        im = np.amax(stack,axis=0)\n",
    "    imC = get_im(Res_mat,im)\n",
    "    \n",
    "    f, [ax,ax1,ax2] = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    c = ['snow','lime']\n",
    "    palette = copy(mapped.value)\n",
    "    palette.set_over(c[0],1.0)\n",
    "    palette.set_bad(c[1],1.0)\n",
    "    zm = ma.masked_where(imC>5,imC)\n",
    "    ax.imshow(zm,cmap=palette,norm=colors.Normalize(vmin=0,vmax=1.0))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    rois = gen_mask_sc(dict_im['ROI_'+id_],cell_num.value,im.shape)\n",
    "    im_rois = get_im(rois,im)\n",
    "    c = ['snow','lime']\n",
    "    palette = copy(mapped.value)\n",
    "    palette.set_over(c[0],1.0)\n",
    "    palette.set_bad(c[1],1.0)\n",
    "    zm2 = ma.masked_where(im_rois>5,im_rois)\n",
    "    \n",
    "    ax1.imshow(zm2,cmap=palette,norm=colors.Normalize(vmin=0,vmax=1.0))\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    plot_traces(dict_im['Signals_extr_'+id_],cell_num.value,ax2)\n",
    "    \n",
    "\n",
    "    \n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(f)\n",
    "        \n",
    "    \n",
    "button.on_click(plot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

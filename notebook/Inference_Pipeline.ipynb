{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "import h5py\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "from visdom import Visdom\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "############### Visualization\n",
    "\n",
    "from ipywidgets import Button, Layout\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display,clear_output,Video\n",
    "from copy import copy\n",
    "import numpy.ma as ma\n",
    "import matplotlib.colors as colors\n",
    "import imageio\n",
    "\n",
    "\n",
    "sys.path.insert(0,'/media/DATA/jbonato/astro_segm/Astro3S/modules/')\n",
    "from gen_single_astro  import filt_im\n",
    "from sel_active_reg_gen import *\n",
    "from model.dense_up import dense_up\n",
    "\n",
    "from test_fun import gen_sc_mask,fix_mask,prob_calc,small_soma_to_proc,common_merge,art_rem_large,art_rem\n",
    "\n",
    "from get_traces import update_dict_DNN\n",
    "from gui_results import layout\n",
    "from mask_roi_from_fiji import create_mask\n",
    "\n",
    "# model to import\n",
    "model = dense_up(3)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device1 = torch.device('cpu')#('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "###\n",
    "MAX_ROI_AREA_PROC=30\n",
    "MU_PX = 1\n",
    "DOMAIN_RADIUS = 60\n",
    "# motion corr in extracting traces\n",
    "motion_corr=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "N=256\n",
    "M=256\n",
    "\n",
    "fov_list = [2]\n",
    "fov_DNN_weights_folder = '/media/DATA/jbonato/astro_segm/weights/dense_up' \n",
    "set_dir='/media/DATA/jbonato/astro_segm/set1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list': [0, 40, 80, 120, 160],\n",
       " 'blocks': 15,\n",
       " 'threads': 32,\n",
       " 'BPM_ratio': 3,\n",
       " 'bb': 96,\n",
       " 'N_pix_st': 100,\n",
       " 'astr_min': 80,\n",
       " 'percentile': 80,\n",
       " 'pad': 5,\n",
       " 'astro_num': 4,\n",
       " 'init_th_': 0.6,\n",
       " 'decr_dim': 10,\n",
       " 'decr_th': 25,\n",
       " 'corr_int': False,\n",
       " 'gpu_flag': True,\n",
       " 'max_min': array([345,  89]),\n",
       " 'th1_p': 0.25,\n",
       " 'th2_p': 0.1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimDataset_test(Dataset):\n",
    "    def __init__(self,image_set):\n",
    "        self.input_images = image_set    \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):        \n",
    "        image = self.input_images[idx]\n",
    "        image = torch.from_numpy(image).float()\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "vis_flag = False\n",
    "##### LOAD PARAM DICT\n",
    "with open(set_dir+'.tmp/dict_dataset1.txt', \"rb\") as fp:   #Pickling\n",
    "    dict_param = pickle.load(fp)\n",
    "max_min = dict_param['max_min']\n",
    "dict_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/DATA/jbonato/segm_project/set/2/TSeries-04082019-1513-1251_Ch2__movie_corrected_aligned.tiff\n",
      "Zones 10\n",
      "%%%%%%%%%%%%%%%%%%%%\n",
      "ROI NUM 5\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 0\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 8)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 1\n",
      "ROIS 1\n",
      "SPLIT DONE (256, 256, 19)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 2\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 6)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 3\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 9)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 4\n",
      "ROIS 6\n",
      "SPLIT DONE (256, 256, 8)\n",
      "Extraction: done\n"
     ]
    }
   ],
   "source": [
    "dict_im = {}\n",
    "dict_im['Astro_domain_radius'] = DOMAIN_RADIUS\n",
    "for jj in fov_list:\n",
    "    #im_list = []\n",
    "    Res_1 = np.zeros((N,M,3))\n",
    "\n",
    "    test_folder_str =str(jj)\n",
    "    if len(test_folder_str)==1:\n",
    "        test_folder_str1='00'+test_folder_str\n",
    "    else:\n",
    "        test_folder_str1='0'+test_folder_str\n",
    "\n",
    "    model.load_state_dict(torch.load(fov_DNN_weights_folder+test_folder_str1+'D1.pt'))\n",
    "    \n",
    "    #collect stack to analyze\n",
    "    \n",
    "    stack_dir = '/media/DATA/jbonato/segm_project/set/'+test_folder_str+'/'\n",
    "\n",
    "    items_stack = os.listdir(stack_dir)\n",
    "\n",
    "    print(stack_dir + items_stack[0])\n",
    "    stack = io.imread(stack_dir + items_stack[0]).astype(np.uint16)\n",
    "    dict_im['t-series_'+test_folder_str1] = stack\n",
    "    frames,_,_ = stack.shape\n",
    "\n",
    "    a_reg = sel_active_reg(stack.astype(np.float32),dict_param)\n",
    "    mask = a_reg.get_mask()\n",
    "    mask = fix_mask(mask)\n",
    "    \n",
    "    #im_list.append([mask,'Active Regions'])\n",
    "    dict_im['Active Regions_'+test_folder_str1] = mask\n",
    "    filter_ = filt_im(stack_dir + items_stack[0],mask,dict_param['bb']-2*dict_param['pad'])\n",
    "    _, image_to_plot = filter_.create_img()\n",
    "    # for other dataset spatia_pp methods can be called from filter_, outputs are stack filtered and spatial map enhanced  \n",
    "    #im_list.append([image_to_plot,'Enhanced'])\n",
    "    dict_im['Enhanced_'+test_folder_str1] = image_to_plot\n",
    "    coord_l = filter_.get_instances()\n",
    "    \n",
    "    assert coord_l!=0, 'Check Active region extraction module'\n",
    "    \n",
    "    \n",
    "    image_stack = np.empty((len(coord_l),dict_param['bb'],dict_param['bb'])) \n",
    "\n",
    "    image_stack,filt_imageL = filter_.save_im()#select the padding val 5 is default\n",
    "    \n",
    "    \n",
    "    image_set = image_stack[:,0,:,:]\n",
    "    image_set = image_set[:,np.newaxis,:,:]\n",
    "\n",
    "    imageL_set = image_to_plot*filt_imageL\n",
    "    imageL_set-=np.mean(imageL_set)\n",
    "    imageL_set= imageL_set[np.newaxis,np.newaxis,:,:]\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()   # Set model to evaluate mode\n",
    "    ######################################## Prob Map\n",
    "    test_datasetL = SimDataset_test(imageL_set)\n",
    "    test_loader = DataLoader(test_datasetL, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    inputs = next(iter(test_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    pred = model(inputs)\n",
    "    \n",
    "    pred_mean = pred.data.cpu().numpy()\n",
    "    del test_datasetL,test_loader, inputs,pred\n",
    "    \n",
    "    mean = pred_mean[0]\n",
    "    maxim = np.amax(mean,axis=0)\n",
    "    mean[mean<maxim]=0\n",
    "        \n",
    "    prob_mapPL,sm_ent = prob_calc(mean[1,:,:],max_min[0],max_min[1])\n",
    "    \n",
    "    #im_list.append([prob_mapPL,'Prob. Map'])\n",
    "    dict_im['Prob. Map PL_'+test_folder_str1] = prob_mapPL\n",
    "    #im_list.append([sm_ent,'Prob. Map'])\n",
    "    dict_im['Prob. Map_'+test_folder_str1] = sm_ent\n",
    "    ########################################## putative single cell\n",
    "    test_dataset_S = SimDataset_test(image_set)\n",
    "    test_loader = DataLoader(test_dataset_S, batch_size=15, shuffle=False, num_workers=0)\n",
    "\n",
    "    \n",
    "    pred_mean=[]\n",
    "    for inputs in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        pred = model(inputs)\n",
    "        pred_mean.append(pred.data.cpu().numpy())\n",
    "        del inputs,pred\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for j in range(1,len(pred_mean)):\n",
    "        pred_mean[0]=np.vstack((pred_mean[0],pred_mean[j]))\n",
    "\n",
    "    prob_map = np.zeros((N,M,2))\n",
    "\n",
    "    for i in range(len(coord_l)):\n",
    "        mean= np.zeros((3,dict_param['bb'],dict_param['bb']))\n",
    "        mean = pred_mean[0][i,:,:,:].copy()\n",
    "        \n",
    "        maxim = np.amax(mean,axis=0)\n",
    "        mean[mean<maxim]=0\n",
    "        mean[mean>=maxim]=1\n",
    "\n",
    "        small_soma = small_soma_to_proc(mean[1,:,:],N = int((2/3)*max_min[1])) ####remove too small somata segmentated\n",
    "        mean[0,:,:]+=small_soma\n",
    "        mean[1,:,:]-=small_soma\n",
    "        \n",
    "        coord = coord_l[i]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],0] += mean[0,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "        Res_1[coord[1]:coord[3],coord[0]:coord[2],1] += mean[1,dict_param['pad']:-dict_param['pad'],dict_param['pad']:-dict_param['pad']]\n",
    "\n",
    "\n",
    "\n",
    "    Res_1[:,:,0] -= Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    ######### can be wrapped\n",
    "    \n",
    "    soma_f = common_merge(Res_1[:,:,1],sm_ent)\n",
    "    Res_1[:,:,1]=soma_f\n",
    "\n",
    "    #remove possible artifacts\n",
    "    small_soma = small_soma_to_proc(Res_1[:,:,1],int(0.9*max_min[1]),dilation=False)\n",
    "    Res_1[:,:,1]-=small_soma\n",
    "\n",
    "    Res_1[:,:,0] = Res_1[:,:,0]-Res_1[:,:,1]\n",
    "    Res_1[Res_1<1]=0\n",
    "    Res_1[Res_1>0]=1\n",
    "\n",
    "    #remove large region classified as soma Area>500\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=int(1.15*max_min[0]))\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "    Res_1_filt,removal = art_rem_large(Res_1[:,:,1],Res_1[:,:,0],N=max_min[0])\n",
    "    if removal<2:\n",
    "        Res_1-=Res_1_filt[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "    #remove processes without soma\n",
    "    Res_1_filt = art_rem(Res_1[:,:,1],Res_1[:,:,0])\n",
    "    Res_1*=Res_1_filt[:,:,np.newaxis]\n",
    "    \n",
    "    dict_im['Final_Mask_'+test_folder_str1] = Res_1\n",
    "    print(20*'%')\n",
    "    #######################################################################################################\n",
    "    #Visualization of images\n",
    "    if vis_flag:\n",
    "        vis = Visdom(port=8097, server=\"http://localhost\",env='inference_plot')\n",
    "        for key in dict_im.keys():\n",
    "            if key in ['Active Regions_'+test_folder_str1,'Enhanced_'+test_folder_str1,'Final_Mask_'+test_folder_str1]:\n",
    "                image = dict_im[key]\n",
    "                fig, ax = plt.subplots(figsize=(4,4))\n",
    "                ax.imshow(image)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(key)\n",
    "                vis.matplot(fig)\n",
    "                plt.close(fig)\n",
    "    \n",
    "    #### Extraction\n",
    "    single_astro_roi = gen_sc_mask(dict_im['Final_Mask_'+test_folder_str1])\n",
    "    dict_im = update_dict_DNN(dict_im,single_astro_roi,test_folder_str1,motion_corr,MAX_ROI_AREA_PROC,MU_PX)\n",
    "    #### save dict\n",
    "    pickle.dump(dict_im, open( \"inference_ex.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56663db1876490b94fbb2960ce023c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(height='400px', width='1200px')), HBox(children=(VBox(children=(Dropdown(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fov_name = []\n",
    "for j in fov_list:\n",
    "    j = str(j)\n",
    "    if len(j)==1:\n",
    "        j='00'+j\n",
    "    else:\n",
    "        j='0'+j\n",
    "    fov_name.append(j)\n",
    "fov_name\n",
    "hbox,button,display_plot = layout(fov_name,dict_im)\n",
    "display(hbox)\n",
    "button.on_click(display_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual curation\n",
    "Export ROIs for ImageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROI_manual_curation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOV 002\n"
     ]
    }
   ],
   "source": [
    "#export ROIs for ImageJ\n",
    "export_roi(dict_im,fov_list,N=256,M=256,folder_save = '/media/DATA/jbonato/astro_segm/notebook/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean dictionary from ROIs and extracted traces\n",
    "dict_im = clean_dict(dict_im,fov_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROI 5\n",
      "ROI NUM 5\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 0\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 10)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 1\n",
      "ROIS 1\n",
      "SPLIT DONE (256, 256, 24)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 2\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 10)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 3\n",
      "ROIS 3\n",
      "SPLIT DONE (256, 256, 11)\n",
      "Extraction: done\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Extracting cell: 4\n",
      "ROIS 4\n",
      "SPLIT DONE (256, 256, 9)\n",
      "Extraction: done\n"
     ]
    }
   ],
   "source": [
    "#update dict_im with the manual curated\n",
    "for fov in fov_list:\n",
    "    folder = f'{str(fov):0>3}'\n",
    "    mask_ret = read_roi_curated(folder,N=256,M=256,folder_read='/media/DATA/jbonato/astro_segm/notebook/')\n",
    "    dict_im = update_dict_DNN(dict_im,mask_ret,folder,motion_corr,MAX_ROI_AREA_PROC,MU_PX)\n",
    "    #### save dict\n",
    "    pickle.dump(dict_im, open( \"inference_ex.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
